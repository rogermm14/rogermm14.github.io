<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Roger Mar√≠ Molas</title>
  
  <meta name="author" content="Roger Mar√≠ Molas">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
	<link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>üåê</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>‚Ä™Roger Mar√≠‚Ä¨ Molas</name>
              </p>
              <p>I am a computer vision research engineer with a PhD and a strong background in image processing and deep learning. My thesis focused on remote sensing and 3D vision tasks (reconstruction, calibration, co-registration, change detection, etc.). My latest works focus on neural rendering techniques applied to remote sensing images, the digitization of cultural heritage and the exploration of generative AI.
              </p>
              <p>
              I am from Barcelona (1995), former student of <a href="https://www.upf.edu/">Universitat Pompeu Fabra</a>. In Barcelona I completed with honors a BSc in Audiovisual Systems Engineering and then a specialized MSc in Computer Vision. I moved to Paris in October 2018 to pursue my PhD under the supervision of <a href="http://dev.ipol.im/~facciolo/">Gabriele Facciolo</a>, at the <a href="https://centreborelli.ens-paris-saclay.fr/en">Centre Borelli</a> (<a href="https://ens-paris-saclay.fr/">ENS Paris-Saclay</a>). I defended my thesis <i><a href="https://www.theses.fr/2022UPASM045">Applications of multi-image remote sensing</a></i> in December 2022. In January 2024 I joined <a href="https://eurecat.org/home/en/">Eurecat</a> where I currently contribute to the coordination and development of AI and computer vision projects in Catalonia and Europe.
              </p>
              <p style="text-align:center">
                <a href="https://scholar.google.com/citations?user=TgpSmIsAAAAJ&hl=en">Google Scholar</a> &nbsp/&nbsp
                <a href="https://www.researchgate.net/profile/Roger-Mari">ResearchGate</a> &nbsp/&nbsp
                <a href="https://www.linkedin.com/in/rogermm14/">LinkedIn</a> &nbsp/&nbsp
                <a href="https://github.com/rogermm14/">GitHub</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/Roger.jpg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Roger_circle.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
                I am interested in computer vision, machine learning, optimization, and image processing. I am particularly passionate about 3D models and the whole process behind their acquisition, generation and assessment.
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

	<tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/ShadowDataset_teaser.png"><img src="images/ShadowDataset_teaser.png" alt="blind-date" width="160" height="160"></a>
	</td>
	<td width="75%" valign="middle">
	<papertitle>S-EO: A Large-Scale Dataset for Geometry-Aware Shadow Detection in Remote Sensing Applications</papertitle>
	<br>
	El√≠as Masquil, <strong>Roger Mar√≠‚Ä¨</strong>, Thibaud Ehret, Enric Meinhardt-Llopis, Pablo Mus√©, Gabriele Facciolo 
	<br>
	<em>CVPR Workshops</em>, 2025
	<br>
	<a href="https://centreborelli.github.io/shadow-eo/">project page</a>
	/
	<a href="https://openaccess.thecvf.com/content/CVPR2025W/EarthVision/papers/Masquil_S-EO_A_Large-Scale_Dataset_for_Geometry-Aware_Shadow_Detection_in_Remote_CVPRW_2025_paper.pdf">paper</a>
	/
	<a href="https://huggingface.co/datasets/emasquil/shadow-eo">data</a>
	<p></p>
	<p>
	This new dataset comprises multi-view satellite images (PAN, RGB), corresponding vegetation and shadow masks, bundle-adjusted RPC camera models and ground-truth DSMs for 702 different geographic areas of 500x500 m each across three different US cities.
	</p>
	</td>
	</tr>			

	<tr onmouseout="mapsLDM_stop()" onmouseover="mapsLDM_start()">
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/mapsLDM_teaser.png">
	<div class="one">
	  <div class="two" id='mapsLDM_image'>
	  <img src='images/mapsLDM_synthetic.png' width="160"></div>
	  <img src='images/mapsLDM_real.png' width="160">
	</div>
	</a>
	<script type="text/javascript">
	  function mapsLDM_start() {
	    document.getElementById('mapsLDM_image').style.opacity = "1";
	  }

	  function mapsLDM_stop() {
	    document.getElementById('mapsLDM_image').style.opacity = "0";
	  }
	  mapsLDM_stop()
	</script>
	</td>
	<td style="padding:20px;width:75%;vertical-align:middle">
	<papertitle>Latent Diffusion Approaches for Conditional Generation of Aerial Imagery: A Study</papertitle>
	<br>
	<strong>Roger Mar√≠‚Ä¨</strong>, Rafael Redondo
	<br>
	<em>IPOL</em>, 2025
	<br>
	<a href="https://www.ipol.im/pub/art/2025/580/">paper</a>
	/
	<a href="https://ipolcore.ipol.im/demo/clientApp/demo.html?id=580">demo</a> 
	/
	<a href="https://github.com/rogermm14/ldm-maps-MLBriefs2024">code</a>
	<p></p>
	<p>
         We evaluate the fidelity and realism of different architectural variations of a latent diffusion model, which is used
to generate RGB aerial images conditioned to semantic maps.
	</p>
	</td>
	</tr>	


	<tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/pansharpenNeRF_teaser.png"><img src="images/pansharpenNeRF_teaser.png" alt="blind-date" width="160" height="160"></a>
	</td>
	<td width="75%" valign="middle">
	<papertitle>Pseudo Pansharpening NeRF for Satellite Image Collections</papertitle>
	<br>
	Emilie Pic, Thibaud Ehret, Gabriele Facciolo, <strong>Roger Mar√≠‚Ä¨</strong>
	<br>
	<em>IGARSS</em>, 2024
	<br>
	<a href="https://hal.science/hal-05073893/document">paper</a>
	<p></p>
	<p>
	EO-NeRF is extended to handle high-res panchromatic (PAN) and low-res multispectral (MS) inputs, eliminating the need for separate pansharpening. The resulting model can render pansharpened image surrogates with high-res color information for each input viewpoint.
	</p>
	</td>
	</tr>


	<tr onmouseout="diffnerf_stop()" onmouseover="diffnerf_start()">
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/diffnerf_teaser.png">
	<div class="one">
	  <div class="two" id='diffnerf_image'>
	  <img src='images/diffnerf_after.png' width="160"></div>
	  <img src='images/diffnerf_before.png' width="160">
	</div>
	</a>
	<script type="text/javascript">
	  function diffnerf_start() {
	    document.getElementById('diffnerf_image').style.opacity = "1";
	  }

	  function diffnerf_stop() {
	    document.getElementById('diffnerf_image').style.opacity = "0";
	  }
	  diffnerf_stop()
	</script>
	</td>
	<td style="padding:20px;width:75%;vertical-align:middle">
	<papertitle>A Generic and Flexible Regularization Framework for NeRFs</papertitle>
	<br>
	Thibaud Ehret, <strong>Roger Mar√≠‚Ä¨</strong>, Gabriele Facciolo
	<br>
	<em>WACV</em>, 2024
	<br>
	<a href="https://openaccess.thecvf.com/content/WACV2024/papers/Ehret_A_Generic_and_Flexible_Regularization_Framework_for_NeRFs_WACV_2024_paper.pdf">paper</a>
	/
	<a href="https://github.com/tehret/diffnerf">code</a>
	/
	<a href="data/DiffNeRF_poster.pdf">poster</a>
	<p></p>
	<p>
	We propose a generic regularization framework for NeRF based on differential geometry that outperforms previous state-of-the-art methods with only three input views. We compare our approach with <a href="https://m-niemeyer.github.io/regnerf/">RegNeRF (CVPR 2022)</a>.
	</p>
	</td>
	</tr>


    <tr onmouseout="eonerf_stop()" onmouseover="eonerf_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <a href="images/EONeRF_after.mp4">
        <div class="one">
          <div class="two" id='eonerf_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/EONeRF_after.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/EONeRF_before.png' width="160">
        </div>
        </a>
        <script type="text/javascript">
          function eonerf_start() {
            document.getElementById('eonerf_image').style.opacity = "1";
          }

          function eonerf_stop() {
            document.getElementById('eonerf_image').style.opacity = "0";
          }
          eonerf_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle>Multi-Date Earth Observation NeRF: The Detail Is in the Shadows</papertitle>
        <br>
        <strong>Roger Mar√≠‚Ä¨</strong>, Gabriele Facciolo, Thibaud Ehret
        <br>
        <em>CVPR Workshops</em>, 2023
        <br>
        <a href="https://rogermm14.github.io/eonerf/">project page</a>
        /
        <a href="https://openaccess.thecvf.com/content/CVPR2023W/EarthVision/papers/Mari_Multi-Date_Earth_Observation_NeRF_The_Detail_Is_in_the_Shadows_CVPRW_2023_paper.pdf">paper</a>
        /
        <a href="https://github.com/rogermm14/eonerf_code">code</a>
        /
	<a href="data/EONeRF_poster.pdf">poster</a>
        <p></p>
        <p>
        We present EO-NeRF, that reveals scene geometry from multi-date satellite images with an unprecedented level of detail. We propose a geometrically consistent shadow model and a radiometric decomposition of the scene adapted to pansharpened satellite images.
        </p>
      </td>
    </tr>


	<tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/Disparity2022_teaser.png"><img src="images/Disparity2022_teaser.png" alt="blind-date" width="160" height="160"></a>
	</td>
	<td width="75%" valign="middle">
	<papertitle>Disparity Estimation Networks for Aerial and High-Resolution Satellite Images: A Review</papertitle>
	<br>
	<strong>Roger Mar√≠‚Ä¨</strong>, Thibaud Ehret, Gabriele Facciolo
	<br>
	<em>IPOL</em>, 2022
	<br>
	<a href="https://www.ipol.im/pub/art/2022/435/">paper</a>
	/
	<a href="https://ipolcore.ipol.im/demo/clientApp/demo.html?id=435">demo</a>
	<p></p>
	<p>
	We evaluate the performance of the deep learning architectures <a href="https://github.com/JiaRenChang/PSMNet">PSM (CVPR 2018)</a> and <a href="https://github.com/gengshan-y/high-res-stereo">HSM (CVPR 2019)</a> for disparity estimation on multiple pairs of high-resolution satellite images.
	</p>
	</td>
	</tr>


	<tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/SatNeRF_teaser2.png"><img src="images/SatNeRF_teaser2.png" alt="blind-date" width="160" height="160"></a>
	</td>
	<td width="75%" valign="middle">
	<papertitle>Sat-NeRF: Learning Multi-View Satellite Photogrammetry With Transient Objects and Shadow Modeling Using RPC Cameras</papertitle>
	<br>
	<strong>Roger Mar√≠‚Ä¨</strong>, Gabriele Facciolo, Thibaud Ehret
	<br>
	<em>CVPR Workshops</em>, 2022
	<br>
	<a href="https://centreborelli.github.io/satnerf/">project page</a>
	/
	<a href="https://openaccess.thecvf.com/content/CVPR2022W/EarthVision/papers/Mari_Sat-NeRF_Learning_Multi-View_Satellite_Photogrammetry_With_Transient_Objects_and_Shadow_CVPRW_2022_paper.pdf">paper</a>
	/
	<a href="https://github.com/centreborelli/satnerf">code</a>
	/
	<a href="data/SatNeRF_poster.pdf">poster</a>
	<p></p>
	<p>
	Sat-NeRF is the first work in neural rendering for multi-date satellite images to demonstrate quantitatively convincing results in terms of surface reconstruction.
	</p>
	</td>
	</tr>


	<tr onmouseout="l1bplus_stop()" onmouseover="l1bplus_start()">
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/L1B+_teaser.png">
	<div class="one">
	  <div class="two" id='l1bplus_image'>
	  <img src='images/L1B+_after.png' width="160"></div>
	  <img src='images/L1B+_before.png' width="160">
	</div>
	</a>
	<script type="text/javascript">
	  function l1bplus_start() {
	    document.getElementById('l1bplus_image').style.opacity = "1";
	  }

	  function l1bplus_stop() {
	    document.getElementById('l1bplus_image').style.opacity = "0";
	  }
	  l1bplus_stop()
	</script>
	</td>
	<td style="padding:20px;width:75%;vertical-align:middle">
	<papertitle>L1B+: A Perfect Sensor Localization Model for Simple Satellite Stereo Reconstruction from Push-Frame Image Strips</papertitle>
	<br>
	<strong>Roger Mar√≠‚Ä¨</strong>, Thibaud Ehret, ‚Ä™J√©r√©my Anger, Carlo de Franchis, Gabriele Facciolo
	<br>
	<em>ISPRS Annals</em>, 2022
	<br>
	<a href="https://isprs-annals.copernicus.org/articles/V-1-2022/137/2022/isprs-annals-V-1-2022-137-2022.pdf">paper</a>
	/
	<a href="data/L1B+_poster.pdf">poster</a>
	<p></p>
	<p>
	We emulate a perfect sensor to generate a single image from a fragmented push-frame strip. The resulting product simplifies large-scale 3D modeling from push-frame imagery.
	</p>
	</td>
	</tr>


	<tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/BAipol_teaser.png"><img src="images/BAipol_teaser.png" alt="blind-date" width="160" height="160"></a>
	</td>
	<td width="75%" valign="middle">
	<papertitle>A Generic Bundle Adjustment Methodology for Indirect RPC Model Refinement of Satellite Imagery</papertitle>
	<br>
	<strong>Roger Mar√≠‚Ä¨</strong>, Carlo de Franchis, Enric Meinhardt-Llopis, ‚Ä™J√©r√©my Anger, Gabriele Facciolo
	<br>
	<em>IPOL</em>, 2021
	<br>
	<a href="https://www.ipol.im/pub/art/2021/352/">paper</a>
	/
	<a href="https://ipolcore.ipol.im/demo/clientApp/demo.html?id=352">demo</a>
	/
	<a href="https://github.com/centreborelli/sat-bundleadjust">code</a>
	<p></p>
	<p>
	We propose a generic bundle adjustment method for multi-view stereo pipelines for satellite images. The RPC camera models of the input views are refined with a rotation that compensates localization errors related to the attitude angles encoding the satellite orientation.
	</p>
	</td>
	</tr>

<tr onmouseout="stockpile_stop()" onmouseover="stockpile_start()">
      <td style="padding:20px;width:25%;vertical-align:middle">
        <a href="images/stockpile_before.png">
        <div class="one">
          <div class="two" id='stockpile_image'><video  width=100% height=100% muted autoplay loop>
          <source src="images/stockpile_after.mp4" type="video/mp4">
          Your browser does not support the video tag.
          </video></div>
          <img src='images/stockpile_before.png' width="160">
        </div>
        </a>
        <script type="text/javascript">
          function stockpile_start() {
            document.getElementById('stockpile_image').style.opacity = "1";
          }

          function stockpile_stop() {
            document.getElementById('stockpile_image').style.opacity = "0";
          }
          stockpile_stop()
        </script>
      </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
        <papertitle>Automatic Stockpile Volume Monitoring Using Multi-View Stereo from SkySat Imagery</papertitle>
        <br>
        <strong>Roger Mar√≠‚Ä¨</strong>, Carlo de Franchis, Enric Meinhardt-Llopis, ‚Ä™Gabriele Facciolo
        <br>
        <em>IGARSS</em>, 2021
        <br>
        <a href="https://arxiv.org/pdf/2103.00945.pdf">paper</a>
        <p></p>
        <p>
        The RPC camera models of a time series of SkySat acquisitions are refined and used to compute a surface model for each date, which is used to measure the stockpile volume.
        </p>
      </td>
    </tr>


	<tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/rpcfit_teaser.png"><img src="images/rpcfit_teaser.png" alt="blind-date" width="160" height="160"></a>
	</td>
	<td width="75%" valign="middle">
	<papertitle>Robust Rational Polynomial Camera Modelling for SAR and Pushbroom Imaging</papertitle>
	<br>
	Roland Akiki, <strong>Roger Mar√≠‚Ä¨</strong>, Carlo de Franchis, Jean-Michel Morel, ‚Ä™Gabriele Facciolo
	<br>
	<em>IGARSS</em>, 2021
	<br>
	<a href="https://arxiv.org/pdf/2102.13423.pdf">paper</a>
	/
	<a href="https://github.com/centreborelli/rpcfit">code</a>
	<p></p>
	<p>
	We describe a terrain-independent algorithm to accurately derive the RPC camera model linking a set of 3D-2D point correspondences based on a regularized least squares fit.
	</p>
	</td>
	</tr>


	<tr>
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/ToBAorNot_teaser.png"><img src="images/ToBAorNot_teaser.png" alt="blind-date" width="160" height="160"></a>
	</td>
	<td width="75%" valign="middle">
	<papertitle>To Bundle Adjust or Not: A Comparison of Relative Geolocation Correction Strategies for Satellite Multi-View Stereo</papertitle>
	<br>
	<strong>Roger Mar√≠‚Ä¨</strong>, Carlo de Franchis, Enric Meinhardt-Llopis, ‚Ä™Gabriele Facciolo
	<br>
	<em>ICCV Workshops</em>, 2019
	<br>
	<a href="https://rogermm14.github.io/bundle-adjust-or-not/">project page</a>
	/
	<a href="https://openaccess.thecvf.com/content_ICCVW_2019/papers/3DRW/Mari_To_Bundle_Adjust_or_Not_A_Comparison_of_Relative_Geolocation_ICCVW_2019_paper.pdf">paper</a>
	/
	<a href="data/ToBAorNot_poster.pdf">poster</a>
	<p></p>
	<p>
	This work investigates and compares different relative geolocation correction techniques for multi-view stereo pipelines for satellite images. We assess the impact on the output geometry.
	</p>
	</td>
	</tr>


	<tr onmouseout="radial_stop()" onmouseover="radial_start()">
	<td style="padding:20px;width:25%;vertical-align:middle">
	<a href="images/radial_teaser.png">
	<div class="one">
	  <div class="two" id='radial_image'>
	  <img src='images/radial_after.png' width="160"></div>
	  <img src='images/radial_before.png' width="160">
	</div>
	</a>
	<script type="text/javascript">
	  function radial_start() {
	    document.getElementById('radial_image').style.opacity = "1";
	  }

	  function radial_stop() {
	    document.getElementById('radial_image').style.opacity = "0";
	  }
	  radial_stop()
	</script>
	</td>
	<td style="padding:20px;width:75%;vertical-align:middle">
	<papertitle>Deep Single Image Camera Calibration with Radial Distortion</papertitle>
	<br>
	Manuel L√≥pez-Antequera, <strong>Roger Mar√≠‚Ä¨</strong>, Pau Gargallo, Yubin Kuang, Javier Gonzalez-Jimenez, Gloria Haro
	<br>
	<em>CVPR</em>, 2019
	<br>
	<a href="https://openaccess.thecvf.com/content_CVPR_2019/papers/Lopez_Deep_Single_Image_Camera_Calibration_With_Radial_Distortion_CVPR_2019_paper.pdf">paper</a>
	/
	<a href="https://openaccess.thecvf.com/content_CVPR_2019/supplemental/Lopez_Deep_Single_Image_CVPR_2019_supplemental.pdf">supp</a>
	<p></p>
	<p>
	We present a deep learning method to predict extrinsic (tilt and roll) and intrinsic (focal length and radial distortion) parameters from a single image. We use a parameterization that is better suited for learning than directly predicting the camera parameters.
	</p>
	</td>
	</tr>






















        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
              <center>
                Design and source code from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron's website</a>.
                </center>
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
